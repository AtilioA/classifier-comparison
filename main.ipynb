{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          zR       NBG\n",
      "0   0.614035  0.964912\n",
      "1   0.614035  0.912281\n",
      "2   0.631579  0.947368\n",
      "3   0.631579  0.929825\n",
      "4   0.631579  0.947368\n",
      "5   0.631579  0.877193\n",
      "6   0.631579  0.947368\n",
      "7   0.631579  0.947368\n",
      "8   0.631579  0.912281\n",
      "9   0.625000  0.910714\n",
      "10  0.614035  0.929825\n",
      "11  0.614035  0.964912\n",
      "12  0.631579  0.982456\n",
      "13  0.631579  0.929825\n",
      "14  0.631579  0.964912\n",
      "15  0.631579  0.947368\n",
      "16  0.631579  0.929825\n",
      "17  0.631579  0.877193\n",
      "18  0.631579  0.877193\n",
      "19  0.625000  0.928571\n",
      "20  0.614035  0.929825\n",
      "21  0.614035  0.964912\n",
      "22  0.631579  0.929825\n",
      "23  0.631579  0.929825\n",
      "24  0.631579  0.929825\n",
      "25  0.631579  0.912281\n",
      "26  0.631579  0.929825\n",
      "27  0.631579  0.964912\n",
      "28  0.631579  0.964912\n",
      "29  0.625000  0.928571\n",
      "zR-NBG Paired T Test:\n",
      "p-value: 1.3542754092366858e-31\n",
      "zR-NBG Wilcoxon Test:\n",
      " p-value: 1.595254879875626e-06\n",
      "\\textbf{Método} & \\textbf{Média} & \\textbf{Desvio Padrão} & \\textbf{Limite Inferior} & \\textbf{Limite Superior} \\ \\hline \n",
      "ZR & 0.63 & 0.01 & 0.62 & 0.63 \\ \\hline \n",
      "NGB & 0.93 & 0.03 & 0.92 & 0.94 \\ \\hline \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importa pacotes necessários via kernel do Jupyter\n",
    "# %pip install numpy seaborn scipy sklearn matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "from sklearn.datasets import load_digits, load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "def create_stats_header():\n",
    "    return '\\\\textbf{Método} & \\\\textbf{Média} & \\\\textbf{Desvio Padrão} & \\\\textbf{Limite Inferior} & \\\\textbf{Limite Superior} \\\\ \\hline \\n'\n",
    "\n",
    "def create_stats_table_line(method_name, mean, std, lower, upper):\n",
    "    return '{} & {:.2f} & {:.2f} & {:.2f} & {:.2f} \\\\ \\hline \\n'.format(method_name, mean, std, lower, upper)\n",
    "\n",
    "# Load digits dataset from scikit-learn; split into data and target/label\n",
    "data, labels = load_breast_cancer(return_X_y=True)\n",
    "# Get the number of samples (lines) and features (columns); also get the number of unique labels, i.e. the number of classes\n",
    "(n_samples, n_features), n_digits = data.shape, np.unique(labels).size\n",
    "# print(f\"- digits: {n_digits}; - samples: {n_samples}; - features: {n_features}\")\n",
    "\n",
    "# Initialize a dummy classifier (zeroR), and the Naive Bayes classifier (GaussianNB)\n",
    "zR = DummyClassifier(strategy='most_frequent')\n",
    "NBG = GaussianNB()\n",
    "\n",
    "# Initialize a scalar pipeline to scale the data before feeding it to the classifier\n",
    "scalar = StandardScaler()\n",
    "\n",
    "pipeline_zR = Pipeline([('transformer', scalar), ('estimator', zR)])\n",
    "pipeline_NBG = Pipeline([('transformer', scalar), ('estimator', NBG)])\n",
    "\n",
    "# Initialize a stratified k-fold cross-validation object with seed provided by the professor\n",
    "RSKF = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=36851234)\n",
    "\n",
    "# Use zeroR (DummyClassifier) and naiveBayes to predict the class of the data with stratified cross-validation (10-fold), repeated 3 times\n",
    "scores_zR = cross_val_score(pipeline_zR, data, labels, scoring='accuracy', cv=RSKF)\n",
    "scores_NBG = cross_val_score(pipeline_NBG, data, labels, scoring='accuracy', cv=RSKF)\n",
    "\n",
    "# Create a dataframe where the columns are the methods and the rows are the scores\n",
    "df_scores = pd.DataFrame(data={'zR': scores_zR, 'NBG': scores_NBG})\n",
    "print(df_scores)\n",
    "\n",
    "# Print the accuracy scores for the classifiers\n",
    "# NBG\n",
    "mean_NBG = scores_NBG.mean()\n",
    "std_NBG = scores_NBG.std()\n",
    "lower_NBG, upper_NBG = stats.norm.interval(0.95, loc=mean_NBG, scale=std_NBG/np.sqrt(len(scores_NBG)))\n",
    "     \n",
    "# print(\"NBG score:\\n\", scores_NBG)\n",
    "# print(\"NBG: Mean Accuracy: %0.2f Standard Deviation: %0.2f\" % (mean_NBG, std_NBG))\n",
    "# print(\"NBG: Accuracy Confidence Interval (95%%): (%0.2f, %0.2f)\\n\" % (lower_NBG, upper_NBG)) \n",
    "       \n",
    "# zR                          \n",
    "mean_zR = scores_zR.mean()\n",
    "std_zR = scores_zR.std()\n",
    "lower_zR, upper_zR = stats.norm.interval(0.95, loc=mean_zR, \n",
    "                               scale=std_zR/np.sqrt(len(scores_zR)))\n",
    "                            \n",
    "\n",
    "# print(\"zR score:\\n\", scores_zR)\n",
    "# print(\"zR: Mean Accuracy: %0.2f Standard Deviation: %0.2f\" % (mean_zR, std_zR))\n",
    "# print(\"zR: Accuracy Confidence Interval (95\\%%): (%0.2f, %0.2f)\\n\" % (lower_zR, upper_zR)) \n",
    "\n",
    "\n",
    "# ZR\n",
    "_, pTValueZrNBG = ttest_rel(scores_zR, scores_NBG)\n",
    "print(f'zR-NBG Paired T Test:\\np-value: {pTValueZrNBG}')\n",
    "\n",
    "_, pWValueZrNBG = wilcoxon(scores_zR, scores_NBG)\n",
    "print(f'zR-NBG Wilcoxon Test:\\n p-value: {pWValueZrNBG}')\n",
    "\n",
    "table = create_stats_header()\n",
    "table += create_stats_table_line('ZR', mean_zR, std_zR, lower_zR, upper_zR)\n",
    "table += create_stats_table_line('NGB', mean_NBG, std_NBG, lower_NBG, upper_NBG)\n",
    "print(table)\n",
    "\n",
    "# conf_mat = confusion_matrix(labels, score_NBG)\n",
    "# print(conf_mat)\n",
    "\n",
    "# plt.matshow(conf_mat, cmap=plt.cm.Blues)\n",
    "# for i in range(len(conf_mat)):\n",
    "#     for j in range(len(conf_mat)):\n",
    "#         plt.text(i, j, conf_mat[i][j], va=\"center\", ha=\"center\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMC score:\n",
      " [0.96666667 0.93333333 0.97777778 0.93888889 0.98333333 0.92222222\n",
      " 0.96111111 0.94972067 0.94413408 0.93854749 0.98333333 0.95\n",
      " 0.93888889 0.95555556 0.95       0.96111111 0.93333333 0.94972067\n",
      " 0.96089385 0.93854749 0.9        0.96666667 0.97222222 0.94444444\n",
      " 0.94444444 0.95       0.93333333 0.95530726 0.97206704 0.92178771]\n",
      "KMC: Mean Accuracy: 0.95 Standard Deviation: 0.02\n",
      "KMC: Accuracy Confidence Interval (95\\%): (0.94, 0.96)\n",
      "\n",
      "zR-gNB Paired T Test:\n",
      "p-value: 4.230984524662128e-41\n",
      "zR-gNB Wilcoxon Test:\n",
      " p-value: 1.7083716990437344e-06\n",
      "zR-KNN Paired T Test:\n",
      "p-value: 3.462949310618454e-60\n",
      "zR-KNN Wilcoxon Test:\n",
      " p-value: 1.6363965084210647e-06\n",
      "zR-AD Paired T Test:\n",
      "p-value: 6.756231505708888e-44\n",
      "zR-AD Wilcoxon Test:\n",
      " p-value: 1.7224282827430733e-06\n",
      "zR-KMC Paired T Test:\n",
      "p-value: 2.335308158986351e-49\n",
      "zR-KMC Wilcoxon Test:\n",
      " p-value: 1.7170105183845441e-06\n",
      "gNB-KNN Paired T Test:\n",
      "p-value: 3.952790045634852e-25\n",
      "gNB-KNN Wilcoxon Test:\n",
      " p-value: 1.7180929312456739e-06\n",
      "gNB-AD Paired T Test:\n",
      "p-value: 2.3741481400808743e-11\n",
      "gNB-AD Wilcoxon Test:\n",
      " p-value: 3.1645851012352535e-06\n",
      "gNB-KMC Paired T Test:\n",
      "p-value: 1.133407803931553e-19\n",
      "KNN-AD Paired T Test:\n",
      "p-value: 5.849121624424338e-21\n",
      "KNN-AD Wilcoxon Test:\n",
      " p-value: 1.7245993818153558e-06\n",
      "KNN-KMC Paired T Test:\n",
      "p-value: 3.5794821269298717e-08\n",
      "KNN-KMC Wilcoxon Test:\n",
      " p-value: 7.154322172356157e-06\n"
     ]
    }
   ],
   "source": [
    "# ETAPA 2:\n",
    "# A segunda etapa consiste no treino, validação e teste dos classificadores que precisam de ajuste de hiperparâmetros, isto é, os classificadores KMC, KNN e AD\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils import check_X_y\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# The KMC classifier uses a clustering algorithm to define K groups of examples of each class in the training base.\n",
    "class KMeansCentroidsClassifier(BaseEstimator):\n",
    "    def __init__(self, k=1):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.centroids = []\n",
    "        # self.groups = self.k * self.nClasses\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        x_train, y_train = check_X_y(x_train, y_train)\n",
    "\n",
    "        for _class in np.unique(y_train):\n",
    "            # Initialize KMeans:\n",
    "            km = KMeans(n_clusters=self.k, random_state=36851234)\n",
    "            # Fit KMeans:\n",
    "            km.fit(x_train[y_train == _class], y_train[y_train == _class])\n",
    "            # Append centroids to centroids list:   \n",
    "            self.centroids.append({\"clusters\": km.cluster_centers_, \"class\": _class})\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        classes = []\n",
    "        for x in x_test:\n",
    "            min_dist = np.Inf\n",
    "            \n",
    "            for centroid in self.centroids:\n",
    "                for cluster in centroid[\"clusters\"]:\n",
    "                    dist = np.linalg.norm(x - cluster)\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        _class = centroid[\"class\"]\n",
    "\n",
    "            classes.append(_class)\n",
    "            \n",
    "        return classes\n",
    "                    \n",
    "\n",
    "dKNN = KNeighborsClassifier(weights='distance')\n",
    "pipeline_kNN = Pipeline([('transformer', scalar), ('estimator', dKNN)])\n",
    "KMC = KMeansCentroidsClassifier()\n",
    "pipeline_KMC = Pipeline([('transformer', scalar), ('estimator', KMC)])\n",
    "AD = DecisionTreeClassifier()\n",
    "pipeline_AD = Pipeline([('transformer', scalar), ('estimator', AD)])\n",
    "\n",
    "# Neste caso, o procedimento de treinamento, validação e teste será realizado através de 3 rodadas de ciclos aninhados de validação e teste,\n",
    "# com o ciclo interno de validação contendo 4 folds e o externo de teste com 10 folds.\n",
    "RSKF = RepeatedStratifiedKFold(n_splits=10, n_repeats=3)\n",
    "\n",
    "# A busca em grade (grid search) do ciclo interno deve considerar os seguintes valores de hiperparâmetros de cada técnica de aprendizado:\n",
    "# KMC: [k = 1, 3, 5, 7]\n",
    "# KNN: [n_neighbors = 1, 3, 5, 7]\n",
    "# AD: [max_depth = None, 3, 5, 10]\n",
    "grade_KMC = {'estimator__k': [1, 3, 5, 7]}\n",
    "grade_kNN = {'estimator__n_neighbors': [1, 3, 5, 7]}\n",
    "grade_AD = {'estimator__max_depth': [None, 3, 5, 10]}\n",
    "grid_search_KMC = GridSearchCV(estimator=pipeline_KMC, param_grid=grade_KMC, scoring='accuracy', cv=4)\n",
    "grid_search_kNN = GridSearchCV(estimator=pipeline_kNN, param_grid=grade_kNN, scoring='accuracy', cv=4)\n",
    "grid_search_AD = GridSearchCV(estimator=pipeline_AD, param_grid=grade_AD, scoring='accuracy', cv=4)\n",
    "\n",
    "# Os dados utilizados no conjunto de treino em cada rodada de teste devem ser padronizados (normalização com z-score).\n",
    "# Os valores de padronização obtidos nos dados de treino devem ser utilizados para padronizar os dados do respectivo conjunto de teste.\n",
    "# ?\n",
    "\n",
    "scores_kNN = cross_val_score(grid_search_kNN, digits_data, digits_labels, scoring='accuracy', cv=RSKF)\n",
    "scores_AD = cross_val_score(grid_search_AD, digits_data, digits_labels, scoring='accuracy', cv=RSKF)\n",
    "scores_KMC = cross_val_score(grid_search_KMC, data, labels, scoring='accuracy', cv=RSKF)\n",
    "\n",
    "mean_KMC = scores_KMC.mean()\n",
    "std_KMC = scores_KMC.std()\n",
    "lower_KMC, upper_KMC = stats.norm.interval(0.95, loc=mean_KMC, scale=std_KMC/np.sqrt(len(scores_KMC)))\n",
    "\n",
    "print(\"KMC score:\\n\", scores_KMC)\n",
    "print(\"KMC: Mean Accuracy: %0.2f Standard Deviation: %0.2f\" % (mean_KMC, std_KMC))\n",
    "print(\"KMC: Accuracy Confidence Interval (95\\%%): (%0.2f, %0.2f)\\n\" % (lower_KMC, upper_KMC)) \n",
    "\n",
    "# Create T-test and wilcoxon test for each pair of classifiers: zR, gNB, KNN, AD, KMC\n",
    "# ZR TESTS:\n",
    "# zR-gNB\n",
    "_, pTValueZrGnb = ttest_rel(scores_zR, scores_gNB)\n",
    "print(f'zR-gNB Paired T Test:\\np-value: {pTValueZrGnb}')\n",
    "_, pWValueZrGnb = wilcoxon(scores_zR, scores_gNB)\n",
    "print(f'zR-gNB Wilcoxon Test:\\n p-value: {pWValueZrGnb}')\n",
    "# zR-KNN\n",
    "_, pTValueZrKnn = ttest_rel(scores_zR, scores_kNN)\n",
    "print(f'zR-KNN Paired T Test:\\np-value: {pTValueZrKnn}')\n",
    "_, pWValueZrKnn = wilcoxon(scores_zR, scores_kNN)\n",
    "print(f'zR-KNN Wilcoxon Test:\\n p-value: {pWValueZrKnn}')\n",
    "# zR-AD\n",
    "_, pTValueZrAd = ttest_rel(scores_zR, scores_AD)\n",
    "print(f'zR-AD Paired T Test:\\np-value: {pTValueZrAd}')\n",
    "_, pWValueZrAd = wilcoxon(scores_zR, scores_AD)\n",
    "print(f'zR-AD Wilcoxon Test:\\n p-value: {pWValueZrAd}')\n",
    "# zR-KMC\n",
    "_, pTValueZrKmc = ttest_rel(scores_zR, scores_KMC)\n",
    "print(f'zR-KMC Paired T Test:\\np-value: {pTValueZrKmc}')\n",
    "_, pWValueZrKmc = wilcoxon(scores_zR, scores_KMC)\n",
    "print(f'zR-KMC Wilcoxon Test:\\n p-value: {pWValueZrKmc}')\n",
    "\n",
    "# gNB TESTS:\n",
    "# gNB-KNN\n",
    "_, pTValueGnbKnn = ttest_rel(scores_gNB, scores_kNN)\n",
    "print(f'gNB-KNN Paired T Test:\\np-value: {pTValueGnbKnn}')\n",
    "_, pWValueGnbKnn = wilcoxon(scores_gNB, scores_kNN)\n",
    "print(f'gNB-KNN Wilcoxon Test:\\n p-value: {pWValueGnbKnn}')\n",
    "# gNB-AD\n",
    "_, pTValueGnbAd = ttest_rel(scores_gNB, scores_AD)\n",
    "print(f'gNB-AD Paired T Test:\\np-value: {pTValueGnbAd}')\n",
    "_, pWValueGnbAd = wilcoxon(scores_gNB, scores_AD)\n",
    "print(f'gNB-AD Wilcoxon Test:\\n p-value: {pWValueGnbAd}')\n",
    "# gNB-KMC\n",
    "_, pTValueGnbKmc = ttest_rel(scores_gNB, scores_KMC)\n",
    "print(f'gNB-KMC Paired T Test:\\np-value: {pTValueGnbKmc}')\n",
    "\n",
    "# KNN TESTS:\n",
    "# KNN-AD\n",
    "_, pTValueKnnAd = ttest_rel(scores_kNN, scores_AD)\n",
    "print(f'KNN-AD Paired T Test:\\np-value: {pTValueKnnAd}')\n",
    "_, pWValueKnnAd = wilcoxon(scores_kNN, scores_AD)\n",
    "print(f'KNN-AD Wilcoxon Test:\\n p-value: {pWValueKnnAd}')\n",
    "# KNN-KMC\n",
    "_, pTValueKnnKmc = ttest_rel(scores_kNN, scores_KMC)\n",
    "print(f'KNN-KMC Paired T Test:\\np-value: {pTValueKnnKmc}')\n",
    "_, pWValueKnnKmc = wilcoxon(scores_kNN, scores_KMC)\n",
    "print(f'KNN-KMC Wilcoxon Test:\\n p-value: {pWValueKnnKmc}')\n",
    "\n",
    "# Os resultados de cada classificador devem ser apresentados numa tabela contendo a média das acurácias obtidas em cada fold, o desvio padrão e o intervalo de confiança a 95% de significância dos resultados,"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
