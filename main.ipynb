{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparando pacotes para o notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /usr/lib/python3.10/site-packages (1.22.4)\n",
      "Requirement already satisfied: seaborn in /home/atilioa/.local/lib/python3.10/site-packages (0.11.2)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3.10/site-packages (1.8.1)\n",
      "Requirement already satisfied: sklearn in /home/atilioa/.local/lib/python3.10/site-packages (0.0)\n",
      "Requirement already satisfied: matplotlib in /home/atilioa/.local/lib/python3.10/site-packages (3.5.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/atilioa/.local/lib/python3.10/site-packages (from seaborn) (1.4.2)\n",
      "Requirement already satisfied: scikit-learn in /home/atilioa/.local/lib/python3.10/site-packages (from sklearn) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/atilioa/.local/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/atilioa/.local/lib/python3.10/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3.10/site-packages (from matplotlib) (9.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/atilioa/.local/lib/python3.10/site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/atilioa/.local/lib/python3.10/site-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/atilioa/.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/atilioa/.local/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/atilioa/.local/lib/python3.10/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install packages via Jupyter kernel\n",
    "%pip install numpy seaborn scipy sklearn matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "from sklearn.datasets import load_digits, load_breast_cancer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeira etapa: classificação com ZeroR e Naive Bayes Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- digits: 10; - samples: 1797; - features: 64\n"
     ]
    }
   ],
   "source": [
    "# Load digits dataset from scikit-learn; split into data and target/label\n",
    "data, labels = load_digits(return_X_y=True)\n",
    "# Get the number of samples (lines) and features (columns); also get the number of unique labels, i.e. the number of classes\n",
    "(n_samples, n_features), n_digits = data.shape, np.unique(labels).size\n",
    "print(f\"- digits: {n_digits}; - samples: {n_samples}; - features: {n_features}\")\n",
    "\n",
    "# Initialize a dummy classifier (zeroR), and the Naive Bayes classifier (GaussianNB)\n",
    "zR = DummyClassifier(strategy='most_frequent')\n",
    "NBG = GaussianNB()\n",
    "\n",
    "# Initialize a scalar pipeline to scale the data before feeding it to the classifier\n",
    "scalar = StandardScaler()\n",
    "\n",
    "pipeline_zR = Pipeline([('transformer', scalar), ('estimator', zR)])\n",
    "pipeline_NBG = Pipeline([('transformer', scalar), ('estimator', NBG)])\n",
    "\n",
    "# Initialize a stratified k-fold cross-validation object with seed provided by the professor\n",
    "RSKF = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=36851234)\n",
    "\n",
    "# Use zeroR (DummyClassifier) and naiveBayes to predict the class of the data with stratified cross-validation (10-fold), repeated 3 times\n",
    "scores_zR = cross_val_score(pipeline_zR, data, labels, scoring='accuracy', cv=RSKF)\n",
    "scores_NBG = cross_val_score(pipeline_NBG, data, labels, scoring='accuracy', cv=RSKF)\n",
    "\n",
    "# Create a dataframe where the columns are the methods and the rows are the scores\n",
    "df_scores = pd.DataFrame(data={'zR': scores_zR, 'NBG': scores_NBG})\n",
    "# print(df_scores)\n",
    "\n",
    "# Calculate statistics for the classifiers\n",
    "# zR                          \n",
    "mean_zR = scores_zR.mean()\n",
    "std_zR = scores_zR.std()\n",
    "lower_zR, upper_zR = stats.norm.interval(0.95, loc=mean_zR, \n",
    "                               scale=std_zR/np.sqrt(len(scores_zR)))\n",
    "                               \n",
    "# NBG\n",
    "mean_NBG = scores_NBG.mean()\n",
    "std_NBG = scores_NBG.std()\n",
    "lower_NBG, upper_NBG = stats.norm.interval(0.95, loc=mean_NBG, scale=std_NBG/np.sqrt(len(scores_NBG)))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição do KMC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils import check_X_y\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# The KMC classifier uses a clustering algorithm to define K groups of examples of each class in the training base.\n",
    "class KMeansCentroidsClassifier(BaseEstimator):\n",
    "    def __init__(self, k=1):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.centroids = []\n",
    "\n",
    "    # Fit KMC centroids to the training base\n",
    "    def fit(self, x_train, y_train):\n",
    "        x_train, y_train = check_X_y(x_train, y_train)\n",
    "\n",
    "        # Create k groups for each class\n",
    "        for _class in np.unique(y_train):\n",
    "            # Initialize KMeans:\n",
    "            km = KMeans(n_clusters=self.k)\n",
    "            # Fit KMeans:\n",
    "            km.fit(x_train[y_train == _class], y_train[y_train == _class])\n",
    "            # Append centroids to centroids list:   \n",
    "            self.centroids.append({\"clusters\": km.cluster_centers_, \"class\": _class})\n",
    "\n",
    "    # Find the closest centroid and return its class\n",
    "    def predict(self, x_test):\n",
    "        classes = []\n",
    "        for x in x_test:\n",
    "            min_dist = np.Inf\n",
    "            \n",
    "            for centroid in self.centroids:\n",
    "                for cluster in centroid[\"clusters\"]:\n",
    "                    dist = np.linalg.norm(x - cluster)\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        _class = centroid[\"class\"]\n",
    "\n",
    "            classes.append(_class)\n",
    "            \n",
    "        return classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparando os modelos para a classificação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "dKNN = KNeighborsClassifier(weights='distance')\n",
    "pipeline_kNN = Pipeline([('transformer', scalar), ('estimator', dKNN)])\n",
    "KMC = KMeansCentroidsClassifier()\n",
    "pipeline_KMC = Pipeline([('transformer', scalar), ('estimator', KMC)])\n",
    "AD = DecisionTreeClassifier()\n",
    "pipeline_AD = Pipeline([('transformer', scalar), ('estimator', AD)])\n",
    "\n",
    "# \"Neste caso, o procedimento de treinamento, validação e teste será realizado através de 3 rodadas de ciclos aninhados de validação e teste,\n",
    "# com o ciclo interno de validação contendo 4 folds e o externo de teste com 10 folds.\"\n",
    "RSKF = RepeatedStratifiedKFold(n_splits=10, n_repeats=3)\n",
    "\n",
    "# \"A busca em grade (grid search) do ciclo interno deve considerar os seguintes valores de hiperparâmetros de cada técnica de aprendizado:\n",
    "# KMC: [k = 1, 3, 5, 7]\n",
    "# KNN: [n_neighbors = 1, 3, 5, 7]\n",
    "# AD: [max_depth = None, 3, 5, 10]\"\n",
    "grade_kNN = {'estimator__n_neighbors': [1, 3, 5, 7]}\n",
    "grade_KMC = {'estimator__k': [1, 3, 5, 7]}\n",
    "grade_AD = {'estimator__max_depth': [None, 3, 5, 10]}\n",
    "grid_search_kNN = GridSearchCV(estimator=pipeline_kNN, param_grid=grade_kNN, scoring='accuracy', cv=4)\n",
    "grid_search_KMC = GridSearchCV(estimator=pipeline_KMC, param_grid=grade_KMC, scoring='accuracy', cv=4)\n",
    "grid_search_AD = GridSearchCV(estimator=pipeline_AD, param_grid=grade_AD, scoring='accuracy', cv=4)\n",
    "\n",
    "scores_kNN = cross_val_score(grid_search_kNN, data, labels, scoring='accuracy', cv=RSKF)\n",
    "scores_KMC = cross_val_score(grid_search_KMC, data, labels, scoring='accuracy', cv=RSKF)\n",
    "scores_AD = cross_val_score(grid_search_AD, data, labels, scoring='accuracy', cv=RSKF)\n",
    "\n",
    "mean_kNN = scores_kNN.mean()\n",
    "std_kNN = scores_kNN.std()\n",
    "lower_kNN, upper_kNN = stats.norm.interval(0.95, loc=mean_kNN, scale=std_kNN/np.sqrt(len(scores_kNN)))\n",
    "\n",
    "mean_KMC = scores_KMC.mean()\n",
    "std_KMC = scores_KMC.std()\n",
    "lower_KMC, upper_KMC = stats.norm.interval(0.95, loc=mean_KMC, scale=std_KMC/np.sqrt(len(scores_KMC)))\n",
    "\n",
    "mean_AD = scores_AD.mean()\n",
    "std_AD = scores_AD.std()\n",
    "lower_AD, upper_AD = stats.norm.interval(0.95, loc=mean_AD, scale=std_AD/np.sqrt(len(scores_AD)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções auxiliares para gerar tabelas dos resultados dos experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a pair of scores against each other\n",
    "def test_two_models(scores1, scores2):\n",
    "    pTValue = ttest_rel(scores1, scores2)\n",
    "    pWValue = wilcoxon(scores1, scores2)\n",
    "    return pTValue, pWValue\n",
    "\n",
    "# Test all models against each other\n",
    "def test_models(all_scores):\n",
    "    # Test each model with the other, one by one:\n",
    "    pTValues = []\n",
    "    pWValues = []\n",
    "\n",
    "    testsDict = {}\n",
    "    for i, (model, score) in enumerate(all_scores.items()):\n",
    "        testsDict[model] = []\n",
    "        for j in range(i+1, len(all_scores)):\n",
    "            pTValue, pWValue = test_two_models(score, all_scores[list(all_scores.keys())[j]])\n",
    "            testsDict[model].append({'p': pTValue.pvalue, 'w': pWValue.pvalue})\n",
    "\n",
    "    return testsDict\n",
    "\n",
    "# Create a matrix of all models vs all models\n",
    "def get_statistical_tests_matrix(statisticalTestsDict):\n",
    "    MIN_CONFIDENCE_LEVEL = 0.05\n",
    "    statisticalTestMatrix = [[None for _ in range(len(statisticalTestsDict))] for _ in range(len(statisticalTestsDict))]\n",
    "    \n",
    "    print(\"Statistical tests:\")\n",
    "    \n",
    "    # Iterate over statisticalTestsDict in a cross fashion:\n",
    "    for i, (model, tests) in enumerate(statisticalTestsDict.items()):\n",
    "        # Print model name in the diagonal:\n",
    "        j = i\n",
    "        statisticalTestMatrix[i][j] = model\n",
    "        for test in tests:\n",
    "            j += 1\n",
    "            statisticalTestMatrix[i][j] = round(test['p'], 8)\n",
    "            statisticalTestMatrix[j][i] = round(test['w'], 8)\n",
    "                \n",
    "    return statisticalTestMatrix\n",
    "\n",
    "# Create a LaTeX table of all models vs all models\n",
    "def create_matrix_table(statisticalTestMatrix):\n",
    "    print(\"\\hline\")\n",
    "    for row in statisticalTestMatrix:\n",
    "        for i, cell in enumerate(row):\n",
    "            ending = None\n",
    "            # If cell is not the last in the row:\n",
    "            if i != len(row) - 1:\n",
    "                ending = ' & '\n",
    "            else: \n",
    "                ending = ' \\\\\\\\ \\hline\\n'\n",
    "                \n",
    "            if type(cell) is not str:\n",
    "                if cell > 0.05:\n",
    "                    print(cell, end=ending)\n",
    "                else:\n",
    "                    print(f'\\\\textbf{{{cell}}}', end=ending)\n",
    "            else: \n",
    "                print(cell, end=ending)\n",
    "\n",
    "\n",
    "# Create a header for the LaTeX stats table\n",
    "def create_stats_header():\n",
    "    return '\\\\textbf{Método} & \\\\textbf{Média} & \\\\textbf{Desvio Padrão} & \\\\textbf{Limite Inferior} & \\\\textbf{Limite Superior} \\\\ \\hline \\n'\n",
    "\n",
    "# Create a line for the LaTeX stats table\n",
    "def create_stats_table_line(method_name, mean, std, lower, upper):\n",
    "    return '{} & {:.2f} & {:.2f} & {:.2f} & {:.2f} \\\\\\\\ \\hline \\n'.format(method_name, mean, std, lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical tests:\n",
      "\\hline\n",
      "zR & \\textbf{0.0} & \\textbf{0.0} & \\textbf{0.0} & \\textbf{0.0} \\\\ \\hline\n",
      "\\textbf{1.71e-06} & NBG & \\textbf{0.0} & \\textbf{0.0} & \\textbf{0.0} \\\\ \\hline\n",
      "\\textbf{1.66e-06} & \\textbf{1.72e-06} & kNN & \\textbf{0.0} & \\textbf{2.1e-07} \\\\ \\hline\n",
      "\\textbf{1.71e-06} & \\textbf{2.87e-06} & \\textbf{1.73e-06} & AD & \\textbf{0.0} \\\\ \\hline\n",
      "\\textbf{1.7e-06} & \\textbf{1.73e-06} & \\textbf{1.1e-05} & \\textbf{1.73e-06} & KMC \\\\ \\hline\n",
      "[['zR', 0.0, 0.0, 0.0, 0.0], [1.71e-06, 'NBG', 0.0, 0.0, 0.0], [1.66e-06, 1.72e-06, 'kNN', 0.0, 2.1e-07], [1.71e-06, 2.87e-06, 1.73e-06, 'AD', 0.0], [1.7e-06, 1.73e-06, 1.1e-05, 1.73e-06, 'KMC']]\n",
      "\\textbf{Método} & \\textbf{Média} & \\textbf{Desvio Padrão} & \\textbf{Limite Inferior} & \\textbf{Limite Superior} \\ \\hline \n",
      "ZR & 0.10 & 0.00 & 0.10 & 0.10 \\\\ \\hline \n",
      "NGB & 0.78 & 0.03 & 0.77 & 0.80 \\\\ \\hline \n",
      "KMC & 0.95 & 0.02 & 0.95 & 0.96 \\\\ \\hline \n",
      "KNN & 0.98 & 0.01 & 0.97 & 0.98 \\\\ \\hline \n",
      "AD & 0.86 & 0.03 & 0.85 & 0.87 \\\\ \\hline \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scoresDict = {\n",
    "    'zR': scores_zR,\n",
    "    'NBG': scores_NBG,\n",
    "    'kNN': scores_kNN,\n",
    "    'AD': scores_AD,\n",
    "    'KMC': scores_KMC,\n",
    "}\n",
    "\n",
    "statisticalTestsDict = test_models(scoresDict)\n",
    "\n",
    "# Create the statistical tests results. The diagonal of the matrix contains the names of the models. The upper diagonal contains the p-values of the statistical tests. The lower diagonal contains the Wilcoxon p-values.\n",
    "statisticalTestMatrix = get_statistical_tests_matrix(statisticalTestsDict)\n",
    "create_matrix_table(statisticalTestMatrix)\n",
    "\n",
    "# Add KNN, AD and KMC scores to df_scores:\n",
    "df_scores['KMC'] = scores_KMC\n",
    "df_scores['KNN'] = scores_kNN\n",
    "df_scores['AD'] = scores_AD\n",
    "\n",
    "table = create_stats_header()\n",
    "table += create_stats_table_line('ZR', mean_zR, std_zR, lower_zR, upper_zR)\n",
    "table += create_stats_table_line('NGB', mean_NBG, std_NBG, lower_NBG, upper_NBG)\n",
    "table += create_stats_table_line('KMC', mean_KMC, std_KMC, lower_KMC, upper_KMC)\n",
    "table += create_stats_table_line('KNN', mean_kNN, std_kNN, lower_kNN, upper_kNN)\n",
    "table += create_stats_table_line('AD', mean_AD, std_AD, lower_AD, upper_AD)\n",
    "\n",
    "print(statisticalTestMatrix)\n",
    "print(table)\n",
    "\n",
    "# Draw boxplot of all scores\n",
    "sns.boxplot(data=df_scores)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
